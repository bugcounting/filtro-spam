{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ispezione dei dati\n",
    "\n",
    "Cominciamo a ispezionare i dati che abbiamo a disposizione. \n",
    "In breve, si tratta di una collezione di messaggi di posta elettronica raccolti da varie fonti come mailing list e altre corpora pubbliche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I messaggi sono raggruppati in cartelle a seconda che siano messaggi di **spam** or **ham**. Come sapete i messaggi di **spam** sono quelli indesiderati, mentre i messaggi di **ham** sono quelli legittimo (ossia, l'opposto di spam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo ad esempio il contenuto di un messaggio di spam nella cartella `spam` (sottocartella di `dati`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================\n",
      "\n",
      "Now you can have HUNDREDS of lenders compete for your loan!\n",
      "\n",
      "FACT: Interest Rates are at their lowest point in 40 years!\n",
      "\n",
      "You're eligible even with less than perfect credit !!\n",
      "\n",
      "\t* Refinancing\n",
      "\t* New Home Loans\n",
      "\t* Debt Consolidation\n",
      "\t* Debt Consultation\n",
      "\t* Auto Loans\n",
      "\t* Credit Cards\n",
      "\t* Student Loans\n",
      "\t* Second Mortgage\n",
      "\t* Home Equity\n",
      "\n",
      "This Service is 100% FREE without any obligation.\n",
      "\n",
      "Visit Our Web Site at:  http://61.129.68.19/user0201/index.asp?Afft=QM3\n",
      "\n",
      "============================================================================\n",
      "\n",
      "To Unsubscribe: http://61.129.68.19/light/watch.asp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spam\n",
    "esempio_spam = \"dati/spam/spam_00131\"\n",
    "## apri e stampa il contenuto del file `esempio_spam`\n",
    "print(spam.contenuto_messaggio(esempio_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo intuire si tratta di un messaggio di spam che cerca di vendere un qualche tipo di finanziamento (presumibilmente non molto affidabile!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo ora un esempio di messaggio di ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         |::::::::::::::::::::::::::::::::::::::::::::::::::|\n",
      "\n",
      "                IT's Monday 520      02 September 2002\n",
      "\n",
      "              |::::::::::::::::::::::::::::::::::::::::|\n",
      "\n",
      "\n",
      "\n",
      "STUDENT LIFE BEGINS WITH LINUX\n",
      "by\n",
      "John Sterne\n",
      "\n",
      "The launch last month of a marketing special interest group by the\n",
      "Irish Linux Users Group (ILUG)  -  open source and marketing, it\n",
      "seems, might not be mutually exclusive concepts  -  has already\n",
      "sparked an interesting initiative at University College Cork.  When\n",
      "the new academic year begins at UCC, every incoming student will\n",
      "be offered a copy of Red Hat Linux 7.3.\n",
      "\n",
      "ILUG member Braun Brelin proposed this promotion, when he ran a\n",
      "training class for staff at the UCC computer science department.\n",
      "Brelin, who is the director of technology at OpenApp, says that the\n",
      "Linux offer could be extended to any or all of the other Irish\n",
      "universities.\n",
      "\n",
      "The user group is tapping into an international Red Hat programme\n",
      "that aims to introduce students at all levels to the open source\n",
      "style of computing.  The Linux distributor runs an 'educational\n",
      "channel' to reach this audience, bundling educational software\n",
      "with its operating environment and offering networked support\n",
      "services to eligible applicants.  This scheme was originally designed\n",
      "to suit the educational structures in the US, but is now available to\n",
      "schools and universities throughout the world.\n",
      "\n",
      "Red Hat Linux 7.3 incorporates ease of use and maintenance\n",
      "features and is intended to counter objections that Linux is hard to\n",
      "master on personal systems.\n",
      "\n",
      "The Linux-for-all project at UCC could also raise the profile of Red\n",
      "Hat Ireland.  Based in Cork, this operation has run shared financial\n",
      "services for other Red Hat offices in Europe since 2000.  Until now\n",
      "its involvement with users in Ireland has been fairly limited,\n",
      "although it does sometimes refer them to other Red Hat offices in\n",
      "Europe that offer consulting or technical support services.\n",
      "\n",
      "David Owens, Red Hat's director of global logistics and production,\n",
      "sees the formation of the ILUG marketing group as a reason to take\n",
      "a more proactive approach.  In the last three months, he notes, his\n",
      "office in Cork has received more and more calls from Irish\n",
      "companies that are interested in adopting Linux and has introduced\n",
      "some to Red Hat pre-sales consultants.\n",
      "\n",
      "\n",
      "-------------\n",
      "Many thanks are due to Braun and David for working together on this one.\n",
      "\n",
      "Regards\n",
      "L.\n",
      "\n",
      "-- \n",
      "Irish Linux Users' Group: ilug@linux.ie\n",
      "http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\n",
      "List maintainer: listmaster@linux.ie\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "esempio_ham = \"dati/easy_ham/ham_00098\"\n",
    "## apri e stampa il contenuto del file `esempio_ham`\n",
    "print(spam.contenuto_messaggio(esempio_ham))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo caso si tratta di un messaggio legittimo, che promuove uno \"Linux User Group\" presso qualche gruppo di studenti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un po' di statistiche\n",
    "\n",
    "Analizzeremo i dati a disposizione principalmente in termini di quali parole (**termini**) compaiono più frequentemente in qualunque posizione in un messaggio di spam piuttosto che di ham.\n",
    "\n",
    "Per queste statistiche abbiamo a disposizione due tipi di strutture: la *matrice delle occorrenze* e la *tabella delle frequenze*. Vediamo un esempio di entrambe per l'analisi di tutti i messaggi nella cartella `spam`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrice delle occorrenze\n",
    "\n",
    "Cominciamo dalla matrice delle occorrenze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      absmiddle  absolute  absolutely  absrsj  abstract\n",
      "dati/spam/spam_00291          0         0           0       0         0\n",
      "dati/spam/spam_00024          0         0           0       0         0\n",
      "dati/spam/spam_00038          0         0           0       0         0\n",
      "dati/spam/spam_00360          0         0           0       0         0\n",
      "dati/spam/spam_00400          0         0           0       0         0\n",
      "dati/spam/spam_00075          0         0           0       0         0\n",
      "dati/spam/spam_00461          0         0           0       0         0\n",
      "dati/spam/spam_00137          0         0           0       0         0\n",
      "dati/spam/spam_00084          0         0           0       0         0\n"
     ]
    }
   ],
   "source": [
    "## lista di tutti i file con messaggi nella cartella `dati/spam`\n",
    "lista_spam = spam.messaggi_in_cartella(\"dati/spam/\")\n",
    "## costruiamo la matrice delle occorrenze\n",
    "mo_spam = spam.matrice_occorrenze_termini(lista_spam)\n",
    "## stampiamone il contenuto di una piccola porzione\n",
    "## visto che la matrice è molto grande\n",
    "print(mo_spam.iloc[1:10, 70:75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa piccola porzione della tabella lista 10 messaggi (uno per riga). Le 5 colonne corrispondono a 5 termini incontrati nei messaggi analizzati. I numeri indicano quante volte ciascun termine compare in un dato messaggio. I numeri sono tutti 0 perchè la matrice è molto *sparsa* &mdash; ossia molte parole compaiono solo in alcuni messaggi. Nel suo complesso però, la matrice riporta delle informazioni utili, come vedremo meglio analizzando la tabella delle frequenze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabella delle frequenze\n",
    "Costruiamo la tabella delle frequenze per gli stessi messaggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             conteggio  frequenza   densita\n",
      "accept              28      0.054  0.000157\n",
      "acceptable           3      0.006  0.000017\n",
      "acceptance           5      0.010  0.000028\n",
      "accepted            25      0.046  0.000140\n",
      "accepting            2      0.004  0.000011\n",
      "accesories           1      0.002  0.000006\n",
      "access             106      0.110  0.000594\n",
      "accessible           6      0.012  0.000034\n",
      "accessories          5      0.008  0.000028\n",
      "accident             2      0.004  0.000011\n"
     ]
    }
   ],
   "source": [
    "tf_spam = spam.tabella_frequenze_termini(lista_spam)\n",
    "## stampiamo una porzione della tabella\n",
    "print(tf_spam[90:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso le *righe* corrispondono ai termini. Per ogni termine la tabella riporta:\n",
    "\n",
    "   * il **conteggio**: il numero di volte che il termine compare nei messaggi analizzati\n",
    "   * la **frequenza**: la frazione dei messaggi contiene il termine (una o più volte)\n",
    "   * la **densità**: la frazione di tutte le parole che sono uguali al termine\n",
    "\n",
    "Nelle nostre statistiche useremo principalmente la *frequenza*, ma è interessante anche osservare altre proprietà e statistiche.\n",
    "\n",
    "Vediamo quali sono i termini più frequenti nei messaggi di spam analizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http     0.828\n",
      "com      0.654\n",
      "html     0.552\n",
      "www      0.544\n",
      "email    0.504\n",
      "click    0.488\n",
      "href     0.468\n",
      "list     0.456\n",
      "free     0.454\n",
      "body     0.444\n",
      "Name: frequenza, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## i 10 termini più frequenti in `lista_spam`\n",
    "print(tf_spam[\"frequenza\"].sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualche esempio di ham\n",
    "Costruiamo la tabella delle frequenze per un gruppo di messaggi di *ham* &mdash; ad esempio, quelli nella cartella `dati/easy_ham`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               conteggio  frequenza   densita\n",
      "academic              10     0.0032  0.000034\n",
      "academics              1     0.0004  0.000003\n",
      "academy                7     0.0012  0.000024\n",
      "acadians               1     0.0004  0.000003\n",
      "accel                  1     0.0004  0.000003\n",
      "accelerate             5     0.0020  0.000017\n",
      "accelerated            1     0.0004  0.000003\n",
      "accelerating           4     0.0016  0.000013\n",
      "acceleration          20     0.0020  0.000067\n",
      "accelerations          1     0.0004  0.000003\n"
     ]
    }
   ],
   "source": [
    "lista_easy_ham = spam.messaggi_in_cartella(\"dati/easy_ham/\")\n",
    "tf_easy_ham = spam.tabella_frequenze_termini(lista_easy_ham)\n",
    "print(tf_easy_ham[90:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http        0.7432\n",
      "com         0.6964\n",
      "www         0.5504\n",
      "list        0.3752\n",
      "net         0.3484\n",
      "listinfo    0.3456\n",
      "date        0.3128\n",
      "wrote       0.3080\n",
      "just        0.3012\n",
      "mailing     0.2944\n",
      "Name: frequenza, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## i 10 termini più frequenti in `lista_easy_ham`\n",
    "print(tf_easy_ham[\"frequenza\"].sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come vediamo ci sono molti termini che compaiono in entrambe le top-10, ma con frequenze leggermente diverse.\n",
    "Alcuni termini, come *http* e *com*, sono comuni semplicemente perché compaiono spesso in indirizzi di siti web, che sono comunemente presenti in ogni tipo di messaggio. Altri invece compaiono prevalentemente in un gruppo rispetto all'altro &mdash; come *mailing* e *listinfo* che indicano che molti dei messaggi di ham provengono da mailing list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione bayesiana\n",
    "\n",
    "Supponiamo di incontrare un nuovo messaggio di posta elettronica, che vorremmo classificare automaticamente in **spam** or **ham**. La classificazione sarà basata su una stima empirica, e pertanto sarà espressa in termini di *probabilità*.\n",
    "\n",
    "Precisamente, dato un messaggio $m$, vorremmo calcolare due probabilità:\n",
    "\n",
    "$$p_S = P[ \\text{spam} \\mid m] \\qquad \\text{probabilità che }m\\text{ sia spam}$$\n",
    "$$p_H = P[ \\text{ham} \\mid m] \\qquad \\text{probabilità che }m\\text{ sia ham}$$\n",
    "\n",
    "Se siamo in grado di stimare entrambe le probabilità possiamo classificare $m$.\n",
    "Se $p_S > p_H$ classifichiamo $m$ come spam; altrimenti lo classifichiamo come ham.\n",
    "\n",
    "Per calcolare $P_S$ e $P_H$ applichiamo un risultato fondamentale di statistica detto \"teorema di Bayes\".\n",
    "Vediamo l'applicazione del teorema per calcolare $P_S$:\n",
    "\n",
    "$$p_S = P[ \\text{spam} \\mid m] = \\frac{P[m \\mid \\text{spam}] \\cdot P[\\text{spam}]}{P[m]}$$\n",
    "\n",
    "Il lato destro dell'equazione ci dice che $p_S$ equivale al prodotto di $P[m \\mid \\text{spam}]$ per $P[\\text{spam}]$ diviso per $P[m]$:\n",
    "\n",
    "   * Il termine $P[m \\mid \\text{spam}]$ si chiama **likelihood** e denota la probabilità di incontrare il testo di $m$ tra i messaggi di spam. Nel nostro caso possiamo stimare la likelihood sulla base delle frequenze. Per ogni termine che incontriamo in $m$ cerchiamo la sua frequenza tra tutti i messaggi di spam che abbiamo catalogato come dati. La likelihood è il prodotto di tutte queste frequenze.\n",
    "   * Il termine $P[\\text{spam}]$ si chiama **prior** perché denota la probabilità *a priori* che un messaggio sia spam. A priori significa prima di esaminare il contenuto del messaggio. In poche parole, il prior è una probabilità che ci dice più o meno quanto siano frequenti i messaggi di spam tra la posta che riceviamo.\n",
    "   * Il risultato $p_S$ si chiama **posterior** perché denota la probabilità *a posteriori* &mdash; ossia dopo aver esaminato il contenuto del messaggio. Il posterior è il risultato dell'applicazione della formula.\n",
    "   \n",
    "Il denominatore $P[m]$ non dobbiamo calcolarlo: visto che ci interessa solo se $p_S$ è maggiore o minore di $p_H$, e entrambe le probabilità hanno lo stesso termine $P[m]$ al denominatore, possiamo semplicemente confrontare i numeratori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un esempio di calcolo del posterior\n",
    "Prendiamo un messaggio nuovo, dalla cartella `dati/spam_2`, e calcoliamo la probabilità che sia spam sulla base delle frequenze in `tf_spam` che abbiamo precedentemente calcolato. Ovviamente sappiamo già che stiamo classificando un messaggio di spam, ma questo ci permetto proprio di avere un'idea di come funzioni il calcolo e di che risultati possa dare.\n",
    "\n",
    "Prima di tutto estraiamo tutti i termini che compaiono in un messaggio a caso in `spam_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ability', 'addresses', 'banned', 'best', 'bgcolor', 'body', 'br',\n",
      "       'britney', 'caught', 'click', 'com', 'content', 'don', 'email', 'face',\n",
      "       'following', 'font', 'home', 'href', 'html', 'http', 'link', 'members',\n",
      "       'mouth', 'ms', 'receive', 'removal', 'remove', 'removed', 'removeyou',\n",
      "       'requests', 'respect', 'sans', 'screening', 'serif', 'simply', 'size',\n",
      "       'spears', 'stolen', 'technical', 'text', 'tripod', 'type', 'uk',\n",
      "       'video', 'videotape', 'want', 'wants', 'www'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "esempio_messaggio = \"dati/spam_2/spam_00057\"\n",
    "## lista di tutti i termini in `esempio_messaggio` (le frequenze non ci interessano)\n",
    "termini_messaggio = spam.tabella_frequenze_termini([esempio_messaggio]).index\n",
    "print(termini_messaggio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ogni termine in `termini_messaggio`, cerchiamo la sua frequenza in `tf_spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ability      0.026\n",
      "addresses    0.066\n",
      "best         0.196\n",
      "bgcolor      0.336\n",
      "body         0.444\n",
      "br           0.416\n",
      "caught       0.002\n",
      "click        0.488\n",
      "com          0.654\n",
      "content      0.394\n",
      "don          0.234\n",
      "email        0.504\n",
      "face         0.364\n",
      "following    0.130\n",
      "font         0.426\n",
      "home         0.164\n",
      "href         0.468\n",
      "html         0.552\n",
      "http         0.828\n",
      "link         0.232\n",
      "members      0.050\n",
      "mouth        0.006\n",
      "ms           0.036\n",
      "receive      0.298\n",
      "removal      0.110\n",
      "remove       0.340\n",
      "removed      0.256\n",
      "requests     0.044\n",
      "respect      0.034\n",
      "sans         0.186\n",
      "screening    0.016\n",
      "serif        0.182\n",
      "simply       0.108\n",
      "size         0.428\n",
      "technical    0.022\n",
      "text         0.414\n",
      "type         0.418\n",
      "uk           0.020\n",
      "video        0.026\n",
      "want         0.230\n",
      "wants        0.012\n",
      "www          0.544\n",
      "Name: frequenza, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## lista dei termini trovati sia in `esempio_messaggio` che in `tf_spam`\n",
    "termini_comuni = [t for t in tf_spam.index if t in termini_messaggio]\n",
    "## lista di frequenze dei termini comuni in tabella delle frequenze `tf_spam`\n",
    "frequenze_comuni = tf_spam.loc[termini_comuni][\"frequenza\"]\n",
    "print(frequenze_comuni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine prendiamo il prodotto degli elementi di `frequenze_comuni`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_comuni = frequenze_comuni.product()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso sorge un problema. Il prodotto `likelihood_comuni` comprende solo i termini del messaggio che sono anche presenti nella tabella delle frequenze. Come possiamo stimare la frequenza di altri termini del messaggio (che non abbiamo trovato nella tabella delle frequenze.\n",
    "\n",
    "Strettamente parlando, la frequenza di questi altri termini è zero. Il problema è che questo renderebbe tutto il prodotto (la likelihood) pari a zero. D'altro canto assumere che la frequenza sia veramente zero significa ipotizzare che i nostri messaggi di esempio di spam siano così vari e completi da includere tutte le parole che possiamo trovare in messaggi di spam. Questo è chiaramente non realistico. \n",
    "\n",
    "La soluzione è molto semplice e si basa su un'approssimazione. Ogni volta che troviamo un termine nel messaggio che non abbiamo incontrato prima, vi assegniamo una likelihood molto piccola ma non zero. Ad esempio $10^{-6}$cioé un milionesimo.\n",
    "\n",
    "Completiamo dunque il calcolo della probabilità $p_S$ per il nostro messaggio di esempio, usanto un prior molto generico di $0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7421927562141306e-79\n"
     ]
    }
   ],
   "source": [
    "## likelihood per termini mancanti\n",
    "prob_mancante = 1e-6\n",
    "## ** è l'operatore di elevamento a potenza in Python\n",
    "likelihood_mancanti = prob_mancante ** (len(termini_messaggio) - len(termini_comuni))\n",
    "## likelihood complessiva\n",
    "likelihood = likelihood_comuni * likelihood_mancanti\n",
    "## p_S * P[m]\n",
    "prior = 0.5\n",
    "p_S = likelihood * prior\n",
    "print(p_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilità è minuscola, ma quello che conta è il confronto con l'altra probabilità $p_H$!\n",
    "Calcoliamola per lo stesso messaggio. I passaggi sono identici, con l'unica differenza che ora usiamo la tabella delle frequenze `tf_easy_ham` che si riferisce a messaggi di ham. \n",
    "\n",
    "Inoltre, teniamo presente che il `prior` era la probabilità a priori che un messaggio sia spam. Ora che stiamo calcolando la probabilità che un messaggio sia ham, il `prior` dev'essere la probabilità a priori che un messaggio sia ham. Siccome se un messaggio non è spam è necessariamente ham (classificazione binaria), il prior per l'ham è `1 - prior` dove `prior` è il valore del prior per spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0321110416663504e-100\n"
     ]
    }
   ],
   "source": [
    "## lista dei termini trovati sia in `esempio_messaggio` che in `tf_easy_ham`\n",
    "termini_comuni = [t for t in tf_easy_ham.index if t in termini_messaggio]\n",
    "## lista di frequenze dei termini comuni in tabella delle frequenze `tf_easy_ham`\n",
    "frequenze_comuni = tf_easy_ham.loc[termini_comuni][\"frequenza\"]\n",
    "## prodotto delle frequenze dei termini comuni\n",
    "likelihood_comuni = frequenze_comuni.product()\n",
    "## likelihood per termini mancanti\n",
    "likelihood_mancanti = prob_mancante ** (len(termini_messaggio) - len(termini_comuni))\n",
    "## likelihood complessiva\n",
    "likelihood = likelihood_comuni * likelihood_mancanti\n",
    "## p_H * P[m]\n",
    "p_H = likelihood * (1 - prior)\n",
    "print(p_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siccome $p_S > p_H$ per `esempio_messaggio`, lo classifichiamo come spam. Questo è corretto visto che l'abbiamo proprio preso da una cartella con messaggi di spam!\n",
    "\n",
    "## Automatizzare la classificazione\n",
    "\n",
    "Nel modulo `spam` che abbiamo già usato ripetutamente, c'è anche una funzione `posterior` che calcola la probabilità a posteriori secondo i passaggi che abbiamo visto sopra.\n",
    "\n",
    "Usiamola per ricalcolare $p_S$ e $p_H$ nell'esempio appena sopra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7421927562141306e-79 2.0321110416663504e-100\n"
     ]
    }
   ],
   "source": [
    "p_S = spam.posterior(esempio_messaggio, tf_spam, prior, prob_mancante)\n",
    "p_H = spam.posterior(esempio_messaggio, tf_easy_ham, 1-prior, prob_mancante)\n",
    "print(p_S, p_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correttamente abbiamo ottenuto gli stessi valori di prima.\n",
    "\n",
    "Nel modulo `spam` c'è un'altra funzione, `probabilmente_spam` che calcola le due probabilità a posteriori $p_S$ e $p_H$ e restituisce `True` se $p_S > p_H$ e `False` altrimenti. In poche parole questa funzione è il nostro classificatore, che useremo negli esperimenti successivi. Vediamo come usarla sempre per lo stesso esempio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(spam.probabilmente_spam(esempio_messaggio, tf_spam, tf_easy_ham, prior, prob_mancante))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quanto è preciso il classificatore?\n",
    "\n",
    "Ora che abbiamo tutte le funzioni per costruire e applicare i classificatori, vediamo quanto spesso essi producono una classificazione corretta.\n",
    "\n",
    "Questi sono le raccolte di messagi a nostra disposizione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tre cartelle con messaggi di spam\n",
    "lista_spam = spam.messaggi_in_cartella(\"dati/spam/\")\n",
    "lista_spam_2 = spam.messaggi_in_cartella(\"dati/spam_2/\")\n",
    "lista_lingspam_spam = spam.messaggi_in_cartella(\"dati/lingspam_spam/\")\n",
    "## quattro cartelle con messaggi di ham\n",
    "lista_easy_ham = spam.messaggi_in_cartella(\"dati/easy_ham/\")\n",
    "lista_easy_ham_2 = spam.messaggi_in_cartella(\"dati/easy_ham_2/\")\n",
    "lista_hard_ham = spam.messaggi_in_cartella(\"dati/hard_ham/\")\n",
    "lista_lingspam_ham = spam.messaggi_in_cartella(\"dati/lingspam_ham/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usiamo:\n",
    "\n",
    "   * `lista_spam` come esempi di messaggi di spam\n",
    "   * `lista_easy_ham` come esempi di messaggi di ham\n",
    "   * classifichiamo i messaggi in `lista_spam_2`\n",
    "   \n",
    "Visto che abbiamo già costruito le tabelle delle frequenze `tf_spam` e `tf_easy_ham` possiamo usare `probabilmente_spam` per classificare tutti i messaggi in `lista_spam_2` e vedere quanti sono classificati correttamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.23049391553329\n"
     ]
    }
   ],
   "source": [
    "classificazione_spam_2 = [spam.probabilmente_spam(messaggio, tf_spam, tf_easy_ham, prior, prob_mancante) \n",
    "                          for messaggio in lista_spam_2]\n",
    "## contiamo quanti sono stati classificati come spam\n",
    "corretti = sum(classificazione_spam_2)\n",
    "## la precisione è la percentuale dei messaggi classificati correttamente\n",
    "print(corretti/len(classificazione_spam_2) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificare correttamente il 74% dei messaggi è un buon risultato, considerando che il nostro filtro è molto primitivo e non ha accesso a un insieme di esempi così grande.\n",
    "\n",
    "Adesso vediamo come va con la classificazione di messaggi di ham, ad esempio quelli in `lista_easy_ham_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.71428571428571 %\n"
     ]
    }
   ],
   "source": [
    "classificazione_easy_ham_2 = [spam.probabilmente_spam(messaggio, tf_spam, tf_easy_ham, 1-prior, prob_mancante) \n",
    "                              for messaggio in lista_easy_ham_2]\n",
    "## contiamo quanti sono stati classificati come spam\n",
    "scorretti = sum(classificazione_easy_ham_2)\n",
    "## la precisione è la percentuale dei messaggi classificati correttamente\n",
    "print((1 - (scorretti/len(classificazione_easy_ham_2))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo significa che meno del 2% di questi messaggi di ham sarebbero stati bloccati dal nostro filtro. Niente male!\n",
    "\n",
    "Per concludere, definiamo una funzione che ci permetta di calcolare la precisione di un classificatore variandone facilmente i parametri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precisione(test_spam, test_ham, tf_spam, tf_ham, prior_spam, prob_mancante):\n",
    "    ## classificazione dei messaggi in test_spam, che sono messaggi di spam\n",
    "    classificazione_test_spam = [spam.probabilmente_spam(messaggio, tf_spam, tf_ham, prior_spam, prob_mancante)\n",
    "                                for messaggio in test_spam]\n",
    "    ## classificazione dei messaggi in test_ham, che sono messaggi di ham\n",
    "    classificazione_test_ham = [spam.probabilmente_spam(messaggio, tf_spam, tf_ham, 1-prior_spam, prob_mancante)\n",
    "                                for messaggio in test_ham]\n",
    "    corretti_spam = sum(classificazione_test_spam)\n",
    "    corretti_ham = len(classificazione_test_ham) - sum(classificazione_test_ham)\n",
    "    ## precisione sui messaggi di spam\n",
    "    precisione_spam = corretti_spam/len(classificazione_test_spam)\n",
    "    ## precisione sui messaggi di ham\n",
    "    precisione_ham = corretti_ham/len(classificazione_test_ham)\n",
    "    ## precisione complessiva\n",
    "    precisione = (corretti_spam + corretti_ham)/(len(classificazione_test_spam) + len(classificazione_test_ham))\n",
    "    ## stampiamo le percentuali arrotondate all'unità\n",
    "    print(\"Precisione su spam:\", str(round(100*precisione_spam) + \"%\", \n",
    "          \"Precisione su ham:\", str(round(100*precisione_ham)) + \"%\", \n",
    "          \"Precisione complessiva:\", str(round(100*precisione))) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisione su spam: 74.0 Precisione su ham: 99.0 Precisione complessiva: 86.0\n"
     ]
    }
   ],
   "source": [
    "precisione(lista_spam_2, lista_easy_ham_2, tf_spam, tf_easy_ham, prior, prob_mancante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sperimentiamo!\n",
    "\n",
    "Adesso possiamo provare variazioni nelle nostre ipotesi (il prior e la probabilità che assegniamo a termini mancanti) e nei dati di esempio (le tabelle delle frequenze, che possiamo costruire per altri dataset). Ecco una lista di alcune variazioni che possiamo provare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Fissiamo il prior a un valore inferiore a 0.5, così da dare una probabilità più alta a priori che un messaggio **non** sia spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Cambiamo la probabilità che assegniamo a termini mancanti in un valore più grande o più piccolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Costruiamo un classificatore che usi più dati di esempio. In questo caso ricordiamoci di evitare di usare certi esempi sia per calcolare le tabelle delle frequenze che per provare la classificazione. Questo sarebbe un esercizio artificiale visto che classifica gli stessi messaggi usati per calibrare il classificatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Mescoliamo messaggi da fonti diverse (**spam** e **lingspam** sono due corpora diversi) e vediamo se questo migliora o peggiora la precisione di clasificazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puoi usare lo spazio qui sotto per ogni altro esperimento che vuoi provare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
